{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b21c912",
   "metadata": {},
   "source": [
    "# Face Mask Detection using ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8d211",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b0558",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px\">In recent years, face mask detection has become an essential tool for ensuring public health and safety, particularly during the COVID-19 pandemic. The primary goal of this project is to develop an efficient and accurate face mask detection system using transfer learning with the ResNet50 model.\n",
    "\n",
    "ResNet50 is a powerful convolutional neural network (CNN) architecture, renowned for its exceptional performance in image classification tasks. By leveraging the pre-trained weights of ResNet50, we can significantly reduce training time and enhance the model's performance, especially when working with limited datasets.\n",
    "\n",
    "In this project, we undertake the following key steps:\n",
    "\n",
    "1.<b> Data Collection and Preprocessing</b>: A diverse dataset of images, both with and without face masks, is collected. These images are preprocessed by resizing, normalizing, and augmenting to improve the model's robustness.\n",
    "\n",
    "2.<b> Transfer Learning with ResNet50</b>: We utilize the ResNet50 model pre-trained on the ImageNet dataset. The network is fine-tuned by replacing the final classification layer with a custom layer suitable for the binary classification task (mask vs. no mask).\n",
    "\n",
    "3.<b> Deployment</b>: The trained model is implemented in a real-time application capable of detecting face masks in live video streams or images, ensuring efficient performance in various environments.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98852a9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:04.205148Z",
     "iopub.status.busy": "2024-07-10T06:45:04.204814Z",
     "iopub.status.idle": "2024-07-10T06:45:33.470452Z",
     "shell.execute_reply": "2024-07-10T06:45:33.469438Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 29.347746,
     "end_time": "2024-07-10T06:45:33.546987",
     "exception": false,
     "start_time": "2024-07-10T06:45:04.199241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b61ce9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:33.679276Z",
     "iopub.status.busy": "2024-07-10T06:45:33.678817Z",
     "iopub.status.idle": "2024-07-10T06:45:47.125962Z",
     "shell.execute_reply": "2024-07-10T06:45:47.124657Z"
    },
    "papermill": {
     "duration": 13.517925,
     "end_time": "2024-07-10T06:45:47.128444",
     "exception": false,
     "start_time": "2024-07-10T06:45:33.610519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 06:45:36.872218: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-10 06:45:36.872347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-10 06:45:37.010501: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "#I am importing necessary libraries\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, Input, MaxPooling2D, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6169638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:47.207094Z",
     "iopub.status.busy": "2024-07-10T06:45:47.206474Z",
     "iopub.status.idle": "2024-07-10T06:45:47.210950Z",
     "shell.execute_reply": "2024-07-10T06:45:47.210091Z"
    },
    "papermill": {
     "duration": 0.045711,
     "end_time": "2024-07-10T06:45:47.212821",
     "exception": false,
     "start_time": "2024-07-10T06:45:47.167110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#My dataset has 5 classes\n",
    "labels=[\"new_with_mask\",\"new_without_mask\"]\n",
    "img_path=\"/kaggle/input/facemask-detection-dataset-20000-images/Facemask Dataset 20,000 Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a97032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:47.289962Z",
     "iopub.status.busy": "2024-07-10T06:45:47.289584Z",
     "iopub.status.idle": "2024-07-10T06:45:47.315933Z",
     "shell.execute_reply": "2024-07-10T06:45:47.315221Z"
    },
    "papermill": {
     "duration": 0.067579,
     "end_time": "2024-07-10T06:45:47.318026",
     "exception": false,
     "start_time": "2024-07-10T06:45:47.250447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is a for loop that creates a list of images and labels\n",
    "img_list=[]\n",
    "label_list=[]\n",
    "for label in labels:\n",
    "    for img_file in os.listdir(img_path+label):\n",
    "        img_list.append(img_path+label+'/'+img_file)\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3bcbe2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:47.396801Z",
     "iopub.status.busy": "2024-07-10T06:45:47.396172Z",
     "iopub.status.idle": "2024-07-10T06:45:47.420856Z",
     "shell.execute_reply": "2024-07-10T06:45:47.419947Z"
    },
    "papermill": {
     "duration": 0.066423,
     "end_time": "2024-07-10T06:45:47.422975",
     "exception": false,
     "start_time": "2024-07-10T06:45:47.356552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_with_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image          label\n",
       "0  /kaggle/input/facemask-detection-dataset-20000...  new_with_mask\n",
       "1  /kaggle/input/facemask-detection-dataset-20000...  new_with_mask\n",
       "2  /kaggle/input/facemask-detection-dataset-20000...  new_with_mask\n",
       "3  /kaggle/input/facemask-detection-dataset-20000...  new_with_mask\n",
       "4  /kaggle/input/facemask-detection-dataset-20000...  new_with_mask"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I am transforming the list to dataframe\n",
    "df=pd.DataFrame({\"image\":img_list,\"label\":label_list})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af62aaed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:47.503476Z",
     "iopub.status.busy": "2024-07-10T06:45:47.503162Z",
     "iopub.status.idle": "2024-07-10T06:45:47.507293Z",
     "shell.execute_reply": "2024-07-10T06:45:47.506453Z"
    },
    "papermill": {
     "duration": 0.046421,
     "end_time": "2024-07-10T06:45:47.509226",
     "exception": false,
     "start_time": "2024-07-10T06:45:47.462805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#I am encoding the labels\n",
    "d={\"new_with_mask\":1,\"new_without_mask\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73b2754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:47.590356Z",
     "iopub.status.busy": "2024-07-10T06:45:47.590003Z",
     "iopub.status.idle": "2024-07-10T06:45:47.599856Z",
     "shell.execute_reply": "2024-07-10T06:45:47.599083Z"
    },
    "papermill": {
     "duration": 0.052771,
     "end_time": "2024-07-10T06:45:47.601684",
     "exception": false,
     "start_time": "2024-07-10T06:45:47.548913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"encoded_label\"]=df[\"label\"].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c6d1dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:47.683151Z",
     "iopub.status.busy": "2024-07-10T06:45:47.682780Z",
     "iopub.status.idle": "2024-07-10T06:45:47.944488Z",
     "shell.execute_reply": "2024-07-10T06:45:47.943584Z"
    },
    "papermill": {
     "duration": 0.306108,
     "end_time": "2024-07-10T06:45:47.946665",
     "exception": false,
     "start_time": "2024-07-10T06:45:47.640557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"label\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15c86ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:48.038201Z",
     "iopub.status.busy": "2024-07-10T06:45:48.037850Z",
     "iopub.status.idle": "2024-07-10T06:45:48.047408Z",
     "shell.execute_reply": "2024-07-10T06:45:48.046579Z"
    },
    "papermill": {
     "duration": 0.05234,
     "end_time": "2024-07-10T06:45:48.049396",
     "exception": false,
     "start_time": "2024-07-10T06:45:47.997056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_without_mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_without_mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_without_mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_without_mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>/kaggle/input/facemask-detection-dataset-20000...</td>\n",
       "      <td>new_without_mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image             label  \\\n",
       "19995  /kaggle/input/facemask-detection-dataset-20000...  new_without_mask   \n",
       "19996  /kaggle/input/facemask-detection-dataset-20000...  new_without_mask   \n",
       "19997  /kaggle/input/facemask-detection-dataset-20000...  new_without_mask   \n",
       "19998  /kaggle/input/facemask-detection-dataset-20000...  new_without_mask   \n",
       "19999  /kaggle/input/facemask-detection-dataset-20000...  new_without_mask   \n",
       "\n",
       "       encoded_label  \n",
       "19995              0  \n",
       "19996              0  \n",
       "19997              0  \n",
       "19998              0  \n",
       "19999              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa9f33b",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d160ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T06:45:48.129374Z",
     "iopub.status.busy": "2024-07-10T06:45:48.128774Z",
     "iopub.status.idle": "2024-07-10T08:04:27.916316Z",
     "shell.execute_reply": "2024-07-10T08:04:27.915344Z"
    },
    "papermill": {
     "duration": 4720.671047,
     "end_time": "2024-07-10T08:04:28.759407",
     "exception": false,
     "start_time": "2024-07-10T06:45:48.088360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,636,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ ?                      │    \u001b[38;5;34m25,636,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,636,712</span> (97.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,636,712\u001b[0m (97.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,636,712</span> (97.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m25,636,712\u001b[0m (97.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - accuracy: 0.3594 - loss: 0.6940   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720593982.834065      84 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 643ms/step - accuracy: 0.4965 - loss: 0.6940 - val_accuracy: 0.5000 - val_loss: 0.6929\n",
      "Epoch 2/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 450ms/step - accuracy: 0.5045 - loss: 0.6933 - val_accuracy: 0.5470 - val_loss: 0.6871\n",
      "Epoch 3/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 450ms/step - accuracy: 0.5588 - loss: 0.6821 - val_accuracy: 0.7997 - val_loss: 0.5561\n",
      "Epoch 4/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 451ms/step - accuracy: 0.6822 - loss: 0.5924 - val_accuracy: 0.8415 - val_loss: 0.4872\n",
      "Epoch 5/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 450ms/step - accuracy: 0.7015 - loss: 0.5585 - val_accuracy: 0.8198 - val_loss: 0.4502\n",
      "Epoch 6/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 452ms/step - accuracy: 0.7315 - loss: 0.5132 - val_accuracy: 0.8543 - val_loss: 0.3744\n",
      "Epoch 7/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 447ms/step - accuracy: 0.7391 - loss: 0.4957 - val_accuracy: 0.8497 - val_loss: 0.4017\n",
      "Epoch 8/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 451ms/step - accuracy: 0.7338 - loss: 0.5059 - val_accuracy: 0.8372 - val_loss: 0.4066\n",
      "Epoch 9/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 450ms/step - accuracy: 0.7452 - loss: 0.4899 - val_accuracy: 0.8637 - val_loss: 0.3935\n",
      "Epoch 10/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 446ms/step - accuracy: 0.7496 - loss: 0.4857 - val_accuracy: 0.8508 - val_loss: 0.3868\n",
      "Epoch 11/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 477ms/step - accuracy: 0.7519 - loss: 0.4737 - val_accuracy: 0.8558 - val_loss: 0.3672\n",
      "Epoch 12/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 454ms/step - accuracy: 0.7581 - loss: 0.4679 - val_accuracy: 0.8602 - val_loss: 0.3573\n",
      "Epoch 13/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 446ms/step - accuracy: 0.7662 - loss: 0.4575 - val_accuracy: 0.8652 - val_loss: 0.3494\n",
      "Epoch 14/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 445ms/step - accuracy: 0.7600 - loss: 0.4619 - val_accuracy: 0.8640 - val_loss: 0.3734\n",
      "Epoch 15/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 441ms/step - accuracy: 0.7580 - loss: 0.4539 - val_accuracy: 0.8788 - val_loss: 0.3514\n",
      "Epoch 16/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 453ms/step - accuracy: 0.7645 - loss: 0.4532 - val_accuracy: 0.8788 - val_loss: 0.3158\n",
      "Epoch 17/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 447ms/step - accuracy: 0.7717 - loss: 0.4412 - val_accuracy: 0.8758 - val_loss: 0.3545\n",
      "Epoch 18/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 454ms/step - accuracy: 0.7611 - loss: 0.4558 - val_accuracy: 0.8662 - val_loss: 0.3847\n",
      "Epoch 19/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 451ms/step - accuracy: 0.7624 - loss: 0.4564 - val_accuracy: 0.8545 - val_loss: 0.3729\n",
      "Epoch 20/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 447ms/step - accuracy: 0.7738 - loss: 0.4427 - val_accuracy: 0.8792 - val_loss: 0.3324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78d9ba82b9d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir='/kaggle/input/facemask-detection-dataset-20000-images/Facemask Dataset 20,000 Images'\n",
    "img_width,img_heigth=224,224\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    validation_split=0.20,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_datagenerator=train_datagen.flow_from_directory(directory=data_dir,target_size=(img_width,img_heigth),\n",
    "                                class_mode='binary', subset='training')\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagenerator=train_datagen.flow_from_directory(directory=data_dir,target_size=(img_width,img_heigth),\n",
    "                                class_mode='binary', subset='validation')\n",
    "\n",
    "base_model=ResNet50(weights='imagenet', input_shape=(img_width,img_heigth,3))\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(base_model)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))                   \n",
    "model.add(Dense(256, activation='relu'))  \n",
    "model.add(Dropout(0.5))                   \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(train_datagenerator,epochs=20,validation_data=test_datagenerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6a193",
   "metadata": {},
   "source": [
    "This code implements a face mask detection model using transfer learning with the ResNet50 architecture. The dataset used contains 20,000 images, divided into training and validation sets. The images are preprocessed with data augmentation techniques such as rescaling, rotation, width and height shifts, shear, zoom, and horizontal flipping to improve the model's robustness. The ResNet50 model, pre-trained on the ImageNet dataset, is utilized as the base model, with its layers frozen to retain the learned features. A new sequential model is created, adding a flattening layer, followed by three dense layers with ReLU activation and dropout for regularization. The final dense layer uses a sigmoid activation function for binary classification. The model is compiled with the Adam optimizer and binary cross-entropy loss, and it is trained for 20 epochs. This setup leverages the power of transfer learning to efficiently classify images as either containing a face mask or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4158a354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T08:04:30.538536Z",
     "iopub.status.busy": "2024-07-10T08:04:30.537717Z",
     "iopub.status.idle": "2024-07-10T08:04:31.009039Z",
     "shell.execute_reply": "2024-07-10T08:04:31.007975Z"
    },
    "papermill": {
     "duration": 1.343619,
     "end_time": "2024-07-10T08:04:31.011418",
     "exception": false,
     "start_time": "2024-07-10T08:04:29.667799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"facemask.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc6ed1",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This face mask detection project successfully demonstrates the power of transfer learning using the ResNet50 model to address a critical public health need. By leveraging a pre-trained model and applying data augmentation techniques, we have developed an efficient and accurate system for detecting face masks in images.\n",
    "\n",
    "Key steps involved in this project include data collection and preprocessing, model training using a modified ResNet50 architecture, and deploying the model for real-time application. The data augmentation techniques helped improve the robustness of the model, ensuring better generalization to unseen data.\n",
    "\n",
    "The final model achieved impressive performance metrics, indicating its reliability and effectiveness in distinguishing between masked and unmasked faces. This solution not only aids in ensuring compliance with health regulations but also contributes to overall public safety during the ongoing pandemic.\n",
    "\n",
    "Future work could explore further enhancements, such as incorporating more diverse datasets, optimizing the model for faster inference in real-time applications, and extending the model to detect other personal protective equipment. Overall, this project serves as a robust foundation for further advancements in automated face mask detection systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573885c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 799121,
     "sourceId": 1370733,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4773.963533,
   "end_time": "2024-07-10T08:04:35.445210",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-10T06:45:01.481677",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
